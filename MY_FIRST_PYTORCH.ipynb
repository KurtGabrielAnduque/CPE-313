{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Es8s12hojkOT"
      },
      "outputs": [],
      "source": [
        "# Lets import all the necessaty libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# before we start our work flow we need to call the device that we are currently user\n",
        "# because this is where the models are get stored\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "zu1KGxHYju5o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font size= 6>Importing the dataset</font>"
      ],
      "metadata": {
        "id": "1OKHsMt_kHT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for this time I will use my own dataset which is the omniglot from pytorch"
      ],
      "metadata": {
        "id": "cNAYjUNzkLXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseOmniglot(Dataset):\n",
        "    def __init__(self, root, background=True, transform=None):\n",
        "        self.dataset = datasets.Omniglot(root=root, background=background, download=True, transform=transform)\n",
        "\n",
        "        self.cls_to_indices = {}\n",
        "        for idx in range(len(self.dataset)):\n",
        "            _, label = self.dataset[idx]\n",
        "            if label not in self.cls_to_indices:\n",
        "                self.cls_to_indices[label] = []\n",
        "            self.cls_to_indices[label].append(idx)\n",
        "        self.labels = list(self.cls_to_indices.keys())\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img1, label1 = self.dataset[index]\n",
        "\n",
        "\n",
        "        target = np.random.randint(0, 2)\n",
        "\n",
        "        if target == 1:\n",
        "            siamese_index = index\n",
        "            while siamese_index == index:\n",
        "                siamese_index = random.choice(self.cls_to_indices[label1])\n",
        "        else:\n",
        "            label2 = random.choice(self.labels)\n",
        "            while label2 == label1:\n",
        "                label2 = random.choice(self.labels)\n",
        "            siamese_index = random.choice(self.cls_to_indices[label2])\n",
        "\n",
        "        img2, _ = self.dataset[siamese_index]\n",
        "\n",
        "\n",
        "        return img1, img2, torch.tensor(target, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "metadata": {
        "id": "dCgQ3HvgkPE2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> I dont know alot about data I just look in the documentation about its preparation before loading the whole data"
      ],
      "metadata": {
        "id": "D6anBLgVkWrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)), # this is the default size of omniglot image\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: 1.0 - x) # We need to invert colors\n",
        "])"
      ],
      "metadata": {
        "id": "36ZoZQd1kgIB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64 # this is my default batch size base on my own reference\n",
        "\n",
        "train_ds = SiameseOmniglot(root=\"data\", background=True, transform=transform)\n",
        "test_ds = SiameseOmniglot(root=\"data\", background=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpl1yhDJkpez",
        "outputId": "980b2493-b831-4696-e01d-ceb3e86eba58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.46M/9.46M [00:00<00:00, 111MB/s]\n",
            "100%|██████████| 6.46M/6.46M [00:00<00:00, 61.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets check the result\n",
        "examples = next(iter(train_loader))\n",
        "print(f\"Batch shape: {examples[0].shape}\") # Should be [64, 1, 28, 28]\n",
        "print(f\"Target shape: {examples[2].shape}\") # Should be [64]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA6Uglgfllc2",
        "outputId": "608163ca-3248-4844-d2df-42eb61a34d95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([64, 1, 28, 28])\n",
            "Target shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font size= 6>Creating the Model"
      ],
      "metadata": {
        "id": "Ce9r7Mt2lw9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>I will just create my own simple CNN layer since the size of the image is just small"
      ],
      "metadata": {
        "id": "8wULSbVOl9or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 5 * 5, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        out1 = self.cnn(x1)\n",
        "        out2 = self.cnn(x2)\n",
        "        return out1, out2\n",
        "\n",
        "model = SiameseNet().to(device)"
      ],
      "metadata": {
        "id": "Qrtk6drxl0Gh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets check the model parameters\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0futA55FpEq5",
        "outputId": "908a899a-73ef-43b7-d1b1-b3b3d18f96e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SiameseNet(\n",
              "  (cnn): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Flatten(start_dim=1, end_dim=-1)\n",
              "    (7): Linear(in_features=3200, out_features=256, bias=True)\n",
              "    (8): ReLU()\n",
              "    (9): Linear(in_features=256, out_features=128, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size = 6> Creating custom loss function"
      ],
      "metadata": {
        "id": "zrCotu5Vmcsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I just found out that the validation and the training data of the omniglot are purely different. Wherein we are training in Latin and Greek dataset. But our testing dataset are Tibetian and Sankrit. Because I found out that user Crossentropy as the loss function doesnt work here where the accuracy of the final model is only 0.1%. So I have to look for the documentation and I found another technique of loss function which is the \"ContrastiveLoss\""
      ],
      "metadata": {
        "id": "72KzaVuimiDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super().__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        # Euclidean distance between the two vectors\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        # Loss formula\n",
        "        loss = torch.mean((label) * torch.pow(euclidean_distance, 2) +\n",
        "                          (1-label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        return loss"
      ],
      "metadata": {
        "id": "PdHmC-O7mgSS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = ContrastiveLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)"
      ],
      "metadata": {
        "id": "oWYhhJCToEEU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font size = 6>Training the Model"
      ],
      "metadata": {
        "id": "ZSl180euoEus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    for batch, (img1, img2, target) in enumerate(dataloader):\n",
        "        img1, img2, target = img1.to(device), img2.to(device), target.to(device)\n",
        "\n",
        "        out1, out2 = model(img1, img2)\n",
        "        loss = loss_fn(out1, out2, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print(f\"Train Loss: {loss.item():>7f}\")\n",
        "\n",
        "def test_loop(dataloader, model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # Threshold: If distance < 0.5, we predict they are the SAME character\n",
        "    threshold = 0.5\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img1, img2, target in dataloader:\n",
        "            img1, img2, target = img1.to(device), img2.to(device), target.to(device)\n",
        "            out1, out2 = model(img1, img2)\n",
        "\n",
        "            # Calculate distance\n",
        "            # since the contrastive loss doesn't categorize images into buckets. It acts like a ruler.\n",
        "            distance = F.pairwise_distance(out1, out2)\n",
        "\n",
        "            # Prediction: 1 if dist < threshold else 0\n",
        "            prediction = (distance < threshold).float()\n",
        "\n",
        "            correct += (prediction == target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "    print(f\"Validation Accuracy (Pairwise Verification): {(100*correct/total):>0.1f}%\")"
      ],
      "metadata": {
        "id": "K4xrjQrzoIdN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting Siamese Training...\")\n",
        "for t in range(20):\n",
        "    print(f\"Epoch {t+1}\")\n",
        "    train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    test_loop(test_loader, model)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YieoHvxUoOsO",
        "outputId": "0ba323f7-103a-40b4-ef5c-535b964de21e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Siamese Training...\n",
            "Epoch 1\n",
            "Train Loss: 0.365128\n",
            "Train Loss: 0.127335\n",
            "Train Loss: 0.118228\n",
            "Train Loss: 0.117928\n",
            "Validation Accuracy (Pairwise Verification): 84.6%\n",
            "Epoch 2\n",
            "Train Loss: 0.094132\n",
            "Train Loss: 0.117458\n",
            "Train Loss: 0.082212\n",
            "Train Loss: 0.093559\n",
            "Validation Accuracy (Pairwise Verification): 86.1%\n",
            "Epoch 3\n",
            "Train Loss: 0.089289\n",
            "Train Loss: 0.098420\n",
            "Train Loss: 0.092595\n",
            "Train Loss: 0.084694\n",
            "Validation Accuracy (Pairwise Verification): 87.5%\n",
            "Epoch 4\n",
            "Train Loss: 0.087108\n",
            "Train Loss: 0.087044\n",
            "Train Loss: 0.098247\n",
            "Train Loss: 0.083399\n",
            "Validation Accuracy (Pairwise Verification): 87.8%\n",
            "Epoch 5\n",
            "Train Loss: 0.086476\n",
            "Train Loss: 0.089016\n",
            "Train Loss: 0.101684\n",
            "Train Loss: 0.094478\n",
            "Validation Accuracy (Pairwise Verification): 88.1%\n",
            "Epoch 6\n",
            "Train Loss: 0.104392\n",
            "Train Loss: 0.096088\n",
            "Train Loss: 0.094255\n",
            "Train Loss: 0.077756\n",
            "Validation Accuracy (Pairwise Verification): 88.2%\n",
            "Epoch 7\n",
            "Train Loss: 0.072830\n",
            "Train Loss: 0.074937\n",
            "Train Loss: 0.085536\n",
            "Train Loss: 0.096734\n",
            "Validation Accuracy (Pairwise Verification): 89.4%\n",
            "Epoch 8\n",
            "Train Loss: 0.081640\n",
            "Train Loss: 0.057195\n",
            "Train Loss: 0.091139\n",
            "Train Loss: 0.084283\n",
            "Validation Accuracy (Pairwise Verification): 89.8%\n",
            "Epoch 9\n",
            "Train Loss: 0.064743\n",
            "Train Loss: 0.065129\n",
            "Train Loss: 0.090443\n",
            "Train Loss: 0.065123\n",
            "Validation Accuracy (Pairwise Verification): 89.7%\n",
            "Epoch 10\n",
            "Train Loss: 0.084530\n",
            "Train Loss: 0.054042\n",
            "Train Loss: 0.075749\n",
            "Train Loss: 0.073494\n",
            "Validation Accuracy (Pairwise Verification): 90.0%\n",
            "Epoch 11\n",
            "Train Loss: 0.073289\n",
            "Train Loss: 0.058044\n",
            "Train Loss: 0.081898\n",
            "Train Loss: 0.071945\n",
            "Validation Accuracy (Pairwise Verification): 91.1%\n",
            "Epoch 12\n",
            "Train Loss: 0.056901\n",
            "Train Loss: 0.078394\n",
            "Train Loss: 0.065910\n",
            "Train Loss: 0.052617\n",
            "Validation Accuracy (Pairwise Verification): 90.2%\n",
            "Epoch 13\n",
            "Train Loss: 0.048704\n",
            "Train Loss: 0.044240\n",
            "Train Loss: 0.068122\n",
            "Train Loss: 0.048095\n",
            "Validation Accuracy (Pairwise Verification): 91.2%\n",
            "Epoch 14\n",
            "Train Loss: 0.065614\n",
            "Train Loss: 0.070475\n",
            "Train Loss: 0.065664\n",
            "Train Loss: 0.052579\n",
            "Validation Accuracy (Pairwise Verification): 91.3%\n",
            "Epoch 15\n",
            "Train Loss: 0.059231\n",
            "Train Loss: 0.057645\n",
            "Train Loss: 0.061671\n",
            "Train Loss: 0.062592\n",
            "Validation Accuracy (Pairwise Verification): 91.2%\n",
            "Epoch 16\n",
            "Train Loss: 0.071342\n",
            "Train Loss: 0.063386\n",
            "Train Loss: 0.050426\n",
            "Train Loss: 0.048195\n",
            "Validation Accuracy (Pairwise Verification): 90.5%\n",
            "Epoch 17\n",
            "Train Loss: 0.069020\n",
            "Train Loss: 0.071050\n",
            "Train Loss: 0.075719\n",
            "Train Loss: 0.085490\n",
            "Validation Accuracy (Pairwise Verification): 91.5%\n",
            "Epoch 18\n",
            "Train Loss: 0.055145\n",
            "Train Loss: 0.055287\n",
            "Train Loss: 0.047658\n",
            "Train Loss: 0.069868\n",
            "Validation Accuracy (Pairwise Verification): 90.1%\n",
            "Epoch 19\n",
            "Train Loss: 0.047353\n",
            "Train Loss: 0.045372\n",
            "Train Loss: 0.051566\n",
            "Train Loss: 0.046788\n",
            "Validation Accuracy (Pairwise Verification): 90.7%\n",
            "Epoch 20\n",
            "Train Loss: 0.052449\n",
            "Train Loss: 0.048853\n",
            "Train Loss: 0.055174\n",
            "Train Loss: 0.045024\n",
            "Validation Accuracy (Pairwise Verification): 90.9%\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}